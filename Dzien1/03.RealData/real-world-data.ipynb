{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a33e58",
   "metadata": {},
   "source": [
    "# Badanie danych rzeczywistych\n",
    "Dane przedstawione w materiale edukacyjnym są często niezwykle doskonałe, zaprojektowane tak, aby pokazać uczniom, jak znaleźć jasne relacje między zmiennymi. Dane \"świata rzeczywistego\" są nieco mniej proste.\n",
    "\n",
    "Ze względu na złożoność danych \"rzeczywistych\" musimy sprawdzić nieprzetworzone dane pod kątem problemów przed ich użyciem.\n",
    "\n",
    "W związku z tym najlepszym rozwiązaniem jest sprawdzenie pierwotnych danych i przetworzenie ich przed użyciem, co zmniejsza błędy lub problemy, zwykle usuwając błędne punkty danych lub modyfikując dane w bardziej użyteczny formularz.\n",
    "\n",
    "## Rzeczywiste problemy z danymi\n",
    "Rzeczywiste dane mogą zawierać wiele różnych problemów, które mogą mieć wpływ na użyteczność danych i naszą interpretację wyników.\n",
    "\n",
    "Ważne jest, aby pamiętać, że na większość rzeczywistych danych wpływa czynniki, które nie zostały zarejestrowane w tym czasie. Na przykład możemy mieć tabelę czasów toru wyścigowego obok rozmiarów silnika; ale różne inne czynniki, które nie zostały zapisane, takie jak pogoda, prawdopodobnie również odegrały rolę. W przypadku problemów często możemy zmniejszyć wpływ tych czynników, zwiększając rozmiar zestawu danych.\n",
    "\n",
    "W innych sytuacjach punkty danych, które są wyraźnie poza oczekiwanymi wartościami — znanymi również jako \"wartości odstające\" — czasami mogą być bezpiecznie usuwane z analiz, chociaż musimy zadbać o to, aby nie usuwać punktów danych, które zapewniają rzeczywiste szczegółowe informacje.\n",
    "\n",
    "Innym typowym problemem w rzeczywistych danych jest stronnicza odchylenie. Stronniczość odnosi się do tendencji do wybierania niektórych typów wartości częściej niż inne w sposób, który błędnie przedstawia podstawową populację lub \"rzeczywisty świat\". Stronniczy może być czasami identyfikowany przez eksplorowanie danych, mając na uwadze podstawową wiedzę na temat tego, skąd pochodzą dane.\n",
    "\n",
    "Rzeczywiste dane zawsze będą miały problemy, ale analitycy danych często mogą przezwyciężyć następujące problemy:\n",
    "\n",
    "- Sprawdzanie brakujących wartości i źle zarejestrowanych danych.\n",
    "- Rozważając usunięcie oczywistych wartości odstających.\n",
    "- Badanie, jakie rzeczywiste czynniki mogą mieć wpływ na ich analizę i określenie, czy ich rozmiar zestawu danych jest wystarczająco duży, aby zmniejszyć wpływ tych - czynników.\n",
    "- Sprawdzanie stronniczych danych pierwotnych i rozważenie ich opcji naprawy stronniczych, jeśli zostanie znaleziona."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f075b29",
   "metadata": {},
   "source": [
    "# Eksploracja danych w Pythonie — dane rzeczywiste\n",
    "\n",
    "W tym notatniku zbadasz rozkłady danych, które nie są normalne, oraz nauczysz się wykonywać podstawowe porównania między zmiennymi.\n",
    "\n",
    "## Ładowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544fde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load data from a text file\n",
    "df_students = pd.read_csv('grades.csv',delimiter=',',header='infer')\n",
    "\n",
    "# Remove any rows with missing data\n",
    "df_students = df_students.dropna(axis=0, how='any')\n",
    "\n",
    "# Calculate who passed, assuming '60' is the grade needed to pass\n",
    "passes  = pd.Series(df_students['Grade'] >= 60)\n",
    "\n",
    "# Save who passed to the Pandas dataframe\n",
    "df_students = pd.concat([df_students, passes.rename(\"Pass\")], axis=1)\n",
    "\n",
    "\n",
    "# Print the result out into this notebook\n",
    "print(df_students)\n",
    "\n",
    "\n",
    "# Create a function that we can re-use\n",
    "def show_distribution(var_data):\n",
    "    '''\n",
    "    This function will make a distribution (graph) and display it\n",
    "    '''\n",
    "\n",
    "    # Get statistics\n",
    "    min_val = var_data.min()\n",
    "    max_val = var_data.max()\n",
    "    mean_val = var_data.mean()\n",
    "    med_val = var_data.median()\n",
    "    mod_val = var_data.mode()[0]\n",
    "\n",
    "    print('Minimum:{:.2f}\\nMean:{:.2f}\\nMedian:{:.2f}\\nMode:{:.2f}\\nMaximum:{:.2f}\\n'.format(min_val,\n",
    "                                                                                            mean_val,\n",
    "                                                                                            med_val,\n",
    "                                                                                            mod_val,\n",
    "                                                                                            max_val))\n",
    "\n",
    "    # Create a figure for 2 subplots (2 rows, 1 column)\n",
    "    fig, ax = plt.subplots(2, 1, figsize = (10,4))\n",
    "\n",
    "    # Plot the histogram   \n",
    "    ax[0].hist(var_data)\n",
    "    ax[0].set_ylabel('Frequency')\n",
    "\n",
    "    # Add lines for the mean, median, and mode\n",
    "    ax[0].axvline(x=min_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=mean_val, color = 'cyan', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=med_val, color = 'red', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=mod_val, color = 'yellow', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=max_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
    "\n",
    "    # Plot the boxplot   \n",
    "    ax[1].boxplot(var_data, vert=False)\n",
    "    ax[1].set_xlabel('Value')\n",
    "\n",
    "    # Add a title to the Figure\n",
    "    fig.suptitle('Data Distribution')\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "show_distribution(df_students['Grade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab44924",
   "metadata": {},
   "source": [
    "Jak być może pamiętasz, nasze dane miały średnią i dominantę w centrum, a wartości rozkładały się symetrycznie wokół środka.\n",
    "\n",
    "Teraz przyjrzyjmy się rozkładowi danych dotyczących czasu nauki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the variable to examine\n",
    "col = df_students['StudyHours']\n",
    "# Call the function\n",
    "show_distribution(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787a0c3",
   "metadata": {},
   "source": [
    "Rozkład czasu nauki różni się znacząco od rozkładu ocen.\n",
    "\n",
    "Zauważ, że wąsy na wykresie box zaczynają się dopiero około 6.0, co oznacza, że przeważająca część pierwszego kwartylu danych jest powyżej tej wartości. Minimum oznaczone jest symbolem **o**, co sugeruje, że może być to statystyczny *odstający* (ang. *outlier*): wartość znacząco odbiegająca od reszty rozkładu.\n",
    "\n",
    "Dane odstające mogą wystąpić z różnych powodów. Może student chciał wpisać \"10\" godzin, ale wpisał \"1\" i pominął \"0\". Albo może naprawdę poświęcił bardzo mało czasu na naukę. W każdym razie to anomalia statystyczna, która nie odzwierciedla typowego przypadku. Spójrzmy, jak wygląda rozkład bez tej wartości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afba3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the variable to examine\n",
    "# We will only get students who have studied more than one hour\n",
    "col = df_students[df_students.StudyHours>1]['StudyHours']\n",
    "\n",
    "# Call the function\n",
    "show_distribution(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f269eb",
   "metadata": {},
   "source": [
    "Dla celów dydaktycznych potraktowaliśmy wartość **1** jako prawdziwy odstający i ją wyłączyliśmy. W praktyce jednak rzadko usuwa się wartości skrajne bez dodatkowego uzasadnienia, szczególnie gdy rozmiar próbki jest niewielki. Im mniejsza próbka, tym większe ryzyko, że nie odzwierciedla ona populacji (tu: wszystkich studentów, nie tylko naszych 22). Jeśli pobralibyśmy próbkę 1000 studentów, mogłoby się okazać, że krótkie czasy nauki są całkiem powszechne.\n",
    "\n",
    "Gdy mamy więcej danych, próbka staje się bardziej wiarygodna i łatwiej jest traktować odstające wartości jako obserwacje poza określonymi percentylami, w których znajduje się większość danych. Na przykład poniższy kod używa funkcji **quantile** z Pandas, aby wykluczyć obserwacje poniżej 0.01-tego percentyla (wartość, powyżej której znajduje się 99% danych)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e55ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the 0.01th percentile\n",
    "q01 = df_students.StudyHours.quantile(0.01)\n",
    "# Get the variable to examine\n",
    "col = df_students[df_students.StudyHours>q01]['StudyHours']\n",
    "# Call the function\n",
    "show_distribution(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aefd6d",
   "metadata": {},
   "source": [
    "> **Wskazówka**: Możesz też usunąć wartości odstające na górnym końcu rozkładu, definiując próg jako wysoki percentyl. Na przykład funkcja **quantile** pozwala znaleźć 0.99 percentyl, poniżej którego znajduje się 99% danych.\n",
    "\n",
    "Po usunięciu wartości odstających wykres box pokazuje dane mieszczące się w czterech kwartylach. Zauważ, że rozkład nie jest symetryczny jak w przypadku ocen. Pojawiają się wartości bardzo wysokie — około 16 godzin — ale większość danych mieści się między 7 a 13 godzinami. Kilka ekstremalnie wysokich wartości przesuwa średnią w stronę wyższych wartości.\n",
    "\n",
    "Spójrzmy teraz na gęstość tego rozkładu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_density(var_data):\n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "\n",
    "    # Plot density\n",
    "    var_data.plot.density()\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title('Data Density')\n",
    "\n",
    "    # Show the mean, median, and mode\n",
    "    plt.axvline(x=var_data.mean(), color = 'cyan', linestyle='dashed', linewidth = 2)\n",
    "    plt.axvline(x=var_data.median(), color = 'red', linestyle='dashed', linewidth = 2)\n",
    "    plt.axvline(x=var_data.mode()[0], color = 'yellow', linestyle='dashed', linewidth = 2)\n",
    "\n",
    "    # Show the figure\n",
    "    plt.show()\n",
    "\n",
    "# Get the density of StudyHours\n",
    "show_density(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff8549",
   "metadata": {},
   "source": [
    "Taki rozkład nazywa się *prawoskośnym* (right-skewed). Większość danych skupia się po lewej stronie rozkładu, a długi ogon po prawej wynika z ekstremalnie wysokich wartości, które przesuwają średnią w prawo.\n",
    "\n",
    "**Miary zmienności**\n",
    "\n",
    "Mamy już ogólne pojęcie, gdzie znajduje się środek rozkładów ocen i czasu nauki. Teraz warto sprawdzić inny aspekt — jak bardzo dane są rozproszone?\n",
    "\n",
    "Typowe statystyki mierzące zmienność obejmują:\n",
    "\n",
    "- **Zakres (Range)**: Różnica między maksimum a minimum. Nie ma wbudowanej funkcji o tej nazwie, ale można go łatwo obliczyć jako **max - min**.\n",
    "- **Wariancja (Variance)**: Średnia z kwadratów odchyleń od średniej. Można ją obliczyć funkcją **var**.\n",
    "- **Odchylenie standardowe (Std.Dev)**: Pierwiastek z wariancji. Można je obliczyć funkcją **std**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in ['Grade','StudyHours']:\n",
    "    col = df_students[col_name]\n",
    "    rng = col.max() - col.min()\n",
    "    var = col.var()\n",
    "    std = col.std()\n",
    "    print('\\n{}:\\n - Range: {:.2f}\\n - Variance: {:.2f}\\n - Std.Dev: {:.2f}'.format(col_name, rng, var, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6d97b3",
   "metadata": {},
   "source": [
    "Spośród tych statystyk odchylenie standardowe jest zwykle najbardziej użyteczne. Daje miarę zmienności w tej samej skali co dane (punkty ocen dla kolumny Grade i godziny dla StudyHours). Im większe odchylenie standardowe, tym bardziej wartości odbiegają od średniej — mówiąc prosto, dane są bardziej rozproszone.\n",
    "\n",
    "W przypadku rozkładu *normalnego* odchylenie standardowe wraz z właściwościami tego rozkładu daje dodatkowe wnioski. Uruchom poniższą komórkę, aby zobaczyć zależność między odchyleniami standardowymi a rozkładem normalnym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Get the Grade column\n",
    "col = df_students['Grade']\n",
    "\n",
    "# get the density\n",
    "density = stats.gaussian_kde(col)\n",
    "\n",
    "# Plot the density\n",
    "col.plot.density()\n",
    "\n",
    "# Get the mean and standard deviation\n",
    "s = col.std()\n",
    "m = col.mean()\n",
    "\n",
    "# Annotate 1 stdev\n",
    "x1 = [m-s, m+s]\n",
    "y1 = density(x1)\n",
    "plt.plot(x1,y1, color='magenta')\n",
    "plt.annotate('1 std (68.26%)', (x1[1],y1[1]))\n",
    "\n",
    "# Annotate 2 stdevs\n",
    "x2 = [m-(s*2), m+(s*2)]\n",
    "y2 = density(x2)\n",
    "plt.plot(x2,y2, color='green')\n",
    "plt.annotate('2 std (95.45%)', (x2[1],y2[1]))\n",
    "\n",
    "# Annotate 3 stdevs\n",
    "x3 = [m-(s*3), m+(s*3)]\n",
    "y3 = density(x3)\n",
    "plt.plot(x3,y3, color='orange')\n",
    "plt.annotate('3 std (99.73%)', (x3[1],y3[1]))\n",
    "\n",
    "# Show the location of the mean\n",
    "plt.axvline(col.mean(), color='cyan', linestyle='dashed', linewidth=1)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3f939",
   "metadata": {},
   "source": [
    "Poziome linie pokazują odsetek danych mieszczących się w jednym, dwóch i trzech odchyleniach standardowych od średniej (w obu kierunkach).\n",
    "\n",
    "W dowolnym rozkładzie normalnym:\n",
    "\n",
    "Skoro średnia ocen wynosi 49.18, a odchylenie standardowe 21.74, a rozkład ocen jest w przybliżeniu normalny, można obliczyć, że 68.26% studentów powinno uzyskać ocenę między 27.44 a 70.92.\n",
    "\n",
    "Statystyki opisowe, których używamy do zrozumienia rozkładu zmiennych, są podstawą analizy statystycznej. Ponieważ są tak istotne przy eksploracji danych, obiekt DataFrame ma wbudowaną metodę `describe`, która zwraca podstawowe statystyki dla wszystkich kolumn numerycznych.\n",
    "So, because we know that the mean grade is 49.18, the standard deviation is 21.74, and distribution of grades is approximately normal, we can calculate that 68.26% of students should achieve a grade between 27.44 and 70.92.\n",
    "\n",
    "The descriptive statistics we've used to understand the distribution of the student data variables are the basis of statistical analysis. Because they're such an important part of exploring your data, there's a built-in `describe` method of the DataFrame object that returns the main descriptive statistics for all numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702cae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_students.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba717be",
   "metadata": {},
   "source": [
    "## Porównywanie danych\n",
    "\n",
    "Skoro już wiemy coś o rozkładzie statystycznym danych w zbiorze, możemy zacząć szukać zależności między zmiennymi.\n",
    "\n",
    "Najpierw usuńmy wiersze z wartościami odstającymi, aby otrzymać próbkę reprezentatywną dla typowej grupy studentów. Zidentyfikowaliśmy, że kolumna `StudyHours` zawiera kilka niezwykle niskich wartości, więc je wykluczymy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1468721",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_students[df_students['StudyHours']>1]\n",
    "print(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6aada",
   "metadata": {},
   "source": [
    "### Porównanie zmiennych numerycznych i kategorycznych\n",
    "\n",
    "Dane zawierają dwie zmienne *numeryczne* (`StudyHours` i `Grade`) oraz dwie *kategoryczne* (`Name` i `Pass`). Zacznijmy od porównania kolumny numerycznej `StudyHours` z kategoryczną `Pass`, aby sprawdzić, czy istnieje widoczna zależność między liczbą godzin nauki a zaliczeniem.\n",
    "\n",
    "Aby to porównanie przeprowadzić, stwórzmy wykresy box pokazujące rozkład `StudyHours` dla każdej wartości `Pass` (true i false)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.boxplot(column='StudyHours', by='Pass', figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8fae0",
   "metadata": {},
   "source": [
    "Porównując rozkłady `StudyHours`, widać (co nie jest zaskakujące), że studenci, którzy zaliczyli, zwykle uczyli się dłużej niż ci, którzy nie zdali. Jeśli zatem chcesz przewidzieć, czy student zaliczy, liczba godzin nauki może być dobrym wskaźnikiem.\n",
    "\n",
    "### Porównanie zmiennych numerycznych\n",
    "\n",
    "Teraz porównajmy dwie zmienne numeryczne. Na początek stwórzmy wykres słupkowy pokazujący zarówno oceny, jak i godziny nauki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a9fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot of name vs grade and study hours\n",
    "df_sample.plot(x='Name', y=['Grade','StudyHours'], kind='bar', figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d09f13",
   "metadata": {},
   "source": [
    "Wykres pokazuje słupki zarówno dla ocen, jak i godzin nauki dla każdego studenta, ale trudniej je porównać, ponieważ wartości są na różnych skalach. Oceny mierzy się w punktach (tu od 3 do 97), a czas nauki w godzinach (od 1 do 16).\n",
    "\n",
    "Częstą techniką przy pracy z danymi numerycznymi na różnych skalach jest *normalizacja*, czyli przeskalowanie wartości tak, aby zachowały proporcje, ale były porównywalne. Użyjemy metody *MinMax*, która rozkłada wartości na przedział od 0 do 1. Można to zaimplementować samodzielnie, ale biblioteka **Scikit-Learn** zapewnia gotowy skalownik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8871d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Get a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Create a new dataframe for the scaled values\n",
    "df_normalized = df_sample[['Name', 'Grade', 'StudyHours']].copy()\n",
    "\n",
    "# Normalize the numeric columns\n",
    "df_normalized[['Grade','StudyHours']] = scaler.fit_transform(df_normalized[['Grade','StudyHours']])\n",
    "\n",
    "# Plot the normalized values\n",
    "df_normalized.plot(x='Name', y=['Grade','StudyHours'], kind='bar', figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ddc2ec",
   "metadata": {},
   "source": [
    "Po normalizacji danych łatwiej dostrzec zależność między oceną a czasem nauki. Nie jest to dokładne dopasowanie, ale wyraźnie widać, że studenci z wyższymi ocenami zwykle uczyli się więcej.\n",
    "\n",
    "Wygląda więc na to, że istnieje korelacja między czasem nauki a oceną. Istnieje nawet statystyczna miara korelacji, której można użyć do ilościowego określenia tej zależności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_normalized.Grade.corr(df_normalized.StudyHours))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5bbf0",
   "metadata": {},
   "source": [
    "Statystyka korelacji przyjmuje wartości między -1 a 1 i wskazuje siłę związku. Wartości powyżej 0 oznaczają korelację *dodatnią* (wysokie wartości jednej zmiennej współwystępują z wysokimi wartościami drugiej), natomiast wartości poniżej 0 oznaczają korelację *ujemną*.\n",
    "\n",
    "W tym przypadku wartość korelacji jest bliska 1, co wskazuje na silną dodatnią zależność między czasem nauki a oceną.\n",
    "\n",
    "> **Uwaga**: Dane pokazują korelację, ale korelacja nie oznacza przyczynowości. Innymi słowy, nie należy zakładać, że jedna zmienna powoduje zmianę drugiej tylko na podstawie korelacji. W naszym przykładzie statystyka pokazuje, że studenci z wysokimi ocenami zwykle spędzają więcej czasu na nauce, ale nie dowodzi to, że osiągnęli wysokie oceny *ponieważ* uczyli się więcej. Można równie dobrze błędnie twierdzić, że studenci uczyli się dużo *ponieważ* ich oceny miały być wysokie.\n",
    "\n",
    "Innym sposobem wizualizacji korelacji między dwiema zmiennymi numerycznymi jest wykres *scatter* (punktowy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "df_sample.plot.scatter(title='Study Time vs Grade', x='StudyHours', y='Grade')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ac1ef",
   "metadata": {},
   "source": [
    "Ponownie widoczny jest wzorzec: studenci, którzy uczyli się najwięcej godzin, zwykle osiągali najwyższe oceny.\n",
    "\n",
    "Możemy to zobaczyć wyraźniej, dodając do wykresu linię regresji (linię najlepszego dopasowania), która pokazuje ogólny trend w danych. Zrobimy to za pomocą metody statystycznej zwanej *regresją metodą najmniejszych kwadratów*.\n",
    "\n",
    "Pewnie pamiętasz ze szkoły równanie linii w postaci kierunkowej (slope-intercept):\n",
    "\n",
    "*y = m x + b*\n",
    "\n",
    "W równaniu tym *y* i *x* to zmienne współrzędne, *m* to nachylenie (slope), a *b* to wyraz wolny (punkt przecięcia z osią Y).\n",
    "\n",
    "W naszym przypadku mamy x = `StudyHours` i y = `Grade`. Musimy obliczyć współczynnik kierunkowy i wyraz wolny dla linii, która jest jak najbliżej punktów. Dla każdego x obliczamy wartość *f(x)* na tej linii, a różnica między rzeczywistą wartością y (Grade) a *f(x)* to błąd dopasowania. Celem jest znalezienie linii minimalizującej sumę kwadratów tych błędów.\n",
    "\n",
    "Szczegółowo: dla każdego punktu liczony jest błąd, następnie błąd ten jest podnoszony do kwadratu, a suma tych kwadratów jest minimalizowana — stąd nazwa *methoda najmniejszych kwadratów*.\n",
    "\n",
    "Na szczęście nie musisz implementować tego samodzielnie — pakiet **SciPy** posiada klasę **stats** z metodą **linregress**, która zwraca współczynniki potrzebne do wyznaczenia nachylenia (*m*) i wyrazu wolnego (*b*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "#\n",
    "df_regression = df_sample[['Grade', 'StudyHours']].copy()\n",
    "\n",
    "# Get the regression slope and intercept\n",
    "m, b, r, p, se = stats.linregress(df_regression['StudyHours'], df_regression['Grade'])\n",
    "print('slope: {:.4f}\\ny-intercept: {:.4f}'.format(m,b))\n",
    "print('so...\\n f(x) = {:.4f}x + {:.4f}'.format(m,b))\n",
    "\n",
    "# Use the function (mx + b) to calculate f(x) for each x (StudyHours) value\n",
    "df_regression['fx'] = (m * df_regression['StudyHours']) + b\n",
    "\n",
    "# Calculate the error between f(x) and the actual y (Grade) value\n",
    "df_regression['error'] = df_regression['fx'] - df_regression['Grade']\n",
    "\n",
    "# Create a scatter plot of Grade vs StudyHours\n",
    "df_regression.plot.scatter(x='StudyHours', y='Grade')\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(df_regression['StudyHours'],df_regression['fx'], color='cyan')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87337569",
   "metadata": {},
   "source": [
    "Zauważ, że tym razem wykres zawiera dwa elementy: wykres punktowy (StudyHours vs Grade) oraz linię najlepszego dopasowania opartą na współczynnikach regresji.\n",
    "\n",
    "Współczynniki nachylenia i wyrazu wolnego obliczone dla linii regresji są wyświetlone powyżej wykresu.\n",
    "\n",
    "Linia opiera się na wartościach *f(x)* obliczonych dla każdej wartości `StudyHours`. Uruchom następną komórkę, aby zobaczyć tabelę zawierającą:\n",
    "\n",
    "- `StudyHours` dla każdego studenta\n",
    "- `Grade` uzyskaną przez studenta\n",
    "- obliczoną wartość *f(x)* na podstawie współczynników regresji\n",
    "- *błąd* między obliczoną wartością *f(x)* a rzeczywistą wartością `Grade`\n",
    "\n",
    "Niektóre błędy, zwłaszcza na skrajach, są dość duże (ponad 17 punktów ocen). Ogólnie jednak linia jest całkiem bliska rzeczywistym ocenom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the original x,y values, the f(x) value, and the error\n",
    "print(df_regression[['StudyHours', 'Grade', 'fx', 'error']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28de34f4",
   "metadata": {},
   "source": [
    "### Wykorzystanie współczynników regresji do prognozy\n",
    "\n",
    "Mając współczynniki regresji opisujące zależność między czasem nauki a oceną, możesz użyć ich w funkcji do oszacowania oczekiwanej oceny dla podanej liczby godzin nauki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e6331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function based on our regression coefficients\n",
    "def f(x):\n",
    "    m = 6.3134\n",
    "    b = -17.9164\n",
    "    return m*x + b\n",
    "\n",
    "study_time = 14\n",
    "\n",
    "# Get f(x) for study time\n",
    "prediction = f(study_time)\n",
    "\n",
    "# Grade can't be less than 0 or more than 100\n",
    "expected_grade = max(0,min(100,prediction))\n",
    "\n",
    "#Print the estimated grade\n",
    "print ('Studying for {} hours per week may result in a grade of {:.0f}'.format(study_time, expected_grade))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ca4fa",
   "metadata": {},
   "source": [
    "Zastosowanie metod statystycznych do próbek pozwoliło określić zależność między czasem nauki a oceną oraz zamknąć ją w ogólnej funkcji, którą można użyć do przewidywania oceny dla danej liczby godzin nauki.\n",
    "\n",
    "Ta technika jest w istocie podstawą uczenia maszynowego. Na podstawie próbek zawierających jedną lub więcej *cech* (tutaj liczba godzin nauki) oraz znanej *etykiety* (tutaj otrzymana ocena) możemy wyprowadzić funkcję przewidującą etykiety dla nowych danych wejściowych.\n",
    "\n",
    "## Podsumowanie\n",
    "\n",
    "W tym notatniku omówiliśmy:\n",
    "\n",
    "1. Czym jest wartość odstająca i jak ją usuwać\n",
    "2. Jak dane mogą być skośne\n",
    "3. Jak badać rozrzut danych\n",
    "4. Podstawowe sposoby porównywania zmiennych, takie jak oceny i czas nauki\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
